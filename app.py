import streamlit as st
import yaml
import json
import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import logging
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data_processor import DatasetProcessor
from src.trainer import TrainingManager
from src.quantizer import ModelQuantizer
from src.ollama_integration import OllamaIntegrator
from src.experiment_tracker import ExperimentTracker
from src.utils.memory_monitor import MemoryMonitor
from src.utils.validators import validate_all

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="LLM ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã‚¢ãƒ—ãƒª",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'training_manager' not in st.session_state:
    st.session_state['training_manager'] = None
if 'current_experiment_id' not in st.session_state:
    st.session_state['current_experiment_id'] = None


def load_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open('./config/default_config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        with open('./config/models.yaml', 'r', encoding='utf-8') as f:
            models_config = yaml.safe_load(f)
        
        return config, models_config
    except Exception as e:
        st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}, {}


def sidebar_menu():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
    with st.sidebar:
        st.title("ğŸš€ LLM ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
        st.markdown("---")
        
        menu_options = [
            ("ğŸ  ãƒ›ãƒ¼ãƒ ", "home"),
            ("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™", "dataset"),
            ("ğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", "training"),
            ("ğŸ“¦ é‡å­åŒ–", "quantization"),
            ("ğŸ¤– Ollamaçµ±åˆ", "ollama"),
            ("ğŸ“ˆ å®Ÿé¨“å±¥æ­´", "experiments"),
            ("âš™ï¸ è¨­å®š", "settings")
        ]
        
        selected_page = st.radio(
            "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
            options=[option[1] for option in menu_options],
            format_func=lambda x: next(option[0] for option in menu_options if option[1] == x),
            key="sidebar_menu"
        )
        
        st.markdown("---")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        memory_monitor = MemoryMonitor()
        memory_info = memory_monitor.get_memory_info()
        
        st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        st.metric("ä½¿ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª", f"{memory_info['available_gb']:.1f} GB")
        st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡", f"{memory_info['percent']:.1f}%")
        
        return selected_page


def home_page():
    """ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸"""
    st.title("ğŸš€ LLM ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã‚¢ãƒ—ãƒª")
    st.markdown("MacBook Air M4ç”¨ã®æ—¥æœ¬èªLLMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†", "è‡ªå‹•åŒ–", help="CSV/JSONãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•å‰å‡¦ç†")
        
    with col2:
        st.metric("ğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", "MLXå¯¾å¿œ", help="Apple Siliconæœ€é©åŒ–")
        
    with col3:
        st.metric("ğŸ“¦ é‡å­åŒ–", "GGUFå¤‰æ›", help="Ollamaçµ±åˆå¯¾å¿œ")
    
    st.markdown("---")
    
    # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰
    st.subheader("ğŸ“‹ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")
    
    with st.expander("1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™", expanded=True):
        st.markdown("""
        - CSV/JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        - è‡ªå‹•çš„ãªæ—¥æœ¬èªæ­£è¦åŒ–
        - å“è³ªæ¤œè¨¼ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        """)
    
    with st.expander("2ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ"):
        st.markdown("""
        - ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆELYZA/Gemma2ï¼‰
        - LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ç›£è¦–
        """)
    
    with st.expander("3ï¸âƒ£ é‡å­åŒ–ã¨çµ±åˆ"):
        st.markdown("""
        - GGUFå½¢å¼ã¸ã®å¤‰æ›
        - é‡å­åŒ–å‡¦ç†ï¼ˆQ4/Q5/Q8ï¼‰
        - Ollamaã¸ã®è‡ªå‹•ç™»éŒ²
        """)
    
    # æœ€è¿‘ã®å®Ÿé¨“
    st.subheader("ğŸ“ˆ æœ€è¿‘ã®å®Ÿé¨“")
    experiment_tracker = ExperimentTracker()
    recent_experiments = experiment_tracker.list_experiments(limit=5)
    
    if recent_experiments:
        df = pd.DataFrame([
            {
                'ID': exp['id'][:8],
                'ãƒ¢ãƒ‡ãƒ«': exp['model_name'].split('/')[-1],
                'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': exp['status'],
                'ä½œæˆæ—¥æ™‚': exp['created_at'][:19]
            }
            for exp in recent_experiments
        ])
        st.dataframe(df, use_container_width=True)
    else:
        st.info("ã¾ã å®Ÿé¨“ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“")


def dataset_page():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ãƒšãƒ¼ã‚¸"""
    st.title("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['csv', 'json', 'jsonl', 'txt'],
        help="CSVã€JSONã€JSONLã€TXTãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ"
    )
    
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        temp_path = f"./data/raw/{uploaded_file.name}"
        os.makedirs("./data/raw", exist_ok=True)
        
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        try:
            processor = DatasetProcessor()
            df = processor.load_dataset(temp_path)
            
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            preview_info = processor.get_preview(df)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("è¡Œæ•°", preview_info['shape'][0])
                st.metric("åˆ—æ•°", preview_info['shape'][1])
            
            with col2:
                st.write("**ã‚«ãƒ©ãƒ æƒ…å ±**")
                for col, dtype in preview_info['dtypes'].items():
                    st.write(f"â€¢ {col}: {dtype}")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.write("**ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿**")
            st.dataframe(df.head(), use_container_width=True)
            
            # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            st.subheader("âš™ï¸ å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
            
            col1, col2 = st.columns(2)
            
            with col1:
                normalize_text = st.checkbox("æ—¥æœ¬èªæ­£è¦åŒ–", value=True)
                remove_duplicates = st.checkbox("é‡è¤‡å‰Šé™¤", value=True)
                task_type = st.selectbox(
                    "ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
                    options=['instruction', 'chat', 'qa', 'custom'],
                    format_func=lambda x: {
                        'instruction': 'æŒ‡ç¤ºå®Ÿè¡Œ',
                        'chat': 'ãƒãƒ£ãƒƒãƒˆ',
                        'qa': 'è³ªå•å¿œç­”',
                        'custom': 'ã‚«ã‚¹ã‚¿ãƒ '
                    }[x]
                )
            
            with col2:
                train_ratio = st.slider("è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ¯”ç‡", 0.5, 0.9, 0.8)
                min_length = st.number_input("æœ€å°æ–‡å­—æ•°", 10, 1000, 50)
                output_format = st.selectbox("å‡ºåŠ›å½¢å¼", ['jsonl', 'json', 'csv'])
            
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
            custom_template = None
            if task_type == 'custom':
                st.subheader("ğŸ“ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
                custom_template = st.text_area(
                    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ{column_name}ã§åˆ—ã‚’å‚ç…§ï¼‰",
                    value="### æŒ‡ç¤º:\n{instruction}\n\n### å›ç­”:\n{output}",
                    height=100
                )
            
            # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†é–‹å§‹", type="primary"):
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ä¸­..."):
                    config = {
                        'train_split': train_ratio,
                        'val_split': (1 - train_ratio) * 0.5,
                        'test_split': (1 - train_ratio) * 0.5,
                        'min_text_length': min_length,
                        'remove_duplicates': remove_duplicates,
                        'normalize_japanese': normalize_text
                    }
                    
                    processor_with_config = DatasetProcessor(config)
                    
                    output_dir = f"./data/processed/{uploaded_file.name.split('.')[0]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    
                    result = processor_with_config.process_dataset(
                        temp_path,
                        output_dir,
                        task_type,
                        custom_template,
                        output_format
                    )
                    
                    if result['success']:
                        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†å®Œäº†ï¼")
                        
                        # çµæœè¡¨ç¤º
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å…ƒãƒ‡ãƒ¼ã‚¿", f"{result['original_rows']} è¡Œ")
                        with col2:
                            st.metric("å‡¦ç†å¾Œ", f"{result['cleaned_rows']} è¡Œ")
                        with col3:
                            st.metric("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¾Œ", f"{result['formatted_items']} ä»¶")
                        
                        # åˆ†å‰²çµæœ
                        st.write("**ãƒ‡ãƒ¼ã‚¿åˆ†å‰²çµæœ**")
                        splits_df = pd.DataFrame([
                            {'åˆ†å‰²': 'è¨“ç·´', 'ä»¶æ•°': result['splits']['train']},
                            {'åˆ†å‰²': 'æ¤œè¨¼', 'ä»¶æ•°': result['splits']['val']},
                            {'åˆ†å‰²': 'ãƒ†ã‚¹ãƒˆ', 'ä»¶æ•°': result['splits']['test']}
                        ])
                        st.dataframe(splits_df, use_container_width=True)
                        
                        # å‡ºåŠ›ãƒ‘ã‚¹è¡¨ç¤º
                        st.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
                        
                    else:
                        st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
                        
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def training_page():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒšãƒ¼ã‚¸"""
    st.title("ğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config, models_config = load_config()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    
    model_options = {}
    if 'base_models' in models_config:
        for key, model_info in models_config['base_models'].items():
            model_options[model_info['name']] = model_info['display_name']
    
    selected_model = st.selectbox(
        "ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«",
        options=list(model_options.keys()),
        format_func=lambda x: model_options.get(x, x)
    )
    
    if selected_model and selected_model in [info['name'] for info in models_config.get('base_models', {}).values()]:
        model_info = next(info for info in models_config['base_models'].values() if info['name'] == selected_model)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º", f"{model_info['size_gb']} GB")
        with col2:
            st.metric("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{model_info['context_length']:,}")
        with col3:
            st.metric("æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º", model_info['recommended_batch_size'])
        
        st.info(f"ğŸ“ {model_info['description']}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ")
    
    processed_data_dir = Path("./data/processed")
    if processed_data_dir.exists():
        dataset_dirs = [d for d in processed_data_dir.iterdir() if d.is_dir()]
        
        if dataset_dirs:
            selected_dataset_dir = st.selectbox(
                "å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
                options=dataset_dirs,
                format_func=lambda x: x.name
            )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±è¡¨ç¤º
            if selected_dataset_dir:
                train_file = selected_dataset_dir / "train.jsonl"
                if train_file.exists():
                    with open(train_file, 'r') as f:
                        train_count = sum(1 for _ in f)
                    st.info(f"ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_count:,} ä»¶")
        else:
            st.warning("å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
            selected_dataset_dir = None
    else:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        selected_dataset_dir = None
    
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    st.subheader("âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    
    with st.expander("åŸºæœ¬è¨­å®š", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            batch_size = st.selectbox("ãƒãƒƒãƒã‚µã‚¤ã‚º", [1, 2, 4], index=0)
            learning_rate = st.select_slider(
                "å­¦ç¿’ç‡",
                options=[1e-5, 2e-5, 5e-5, 1e-4, 2e-4],
                value=5e-5,
                format_func=lambda x: f"{x:.0e}"
            )
            num_epochs = st.slider("ã‚¨ãƒãƒƒã‚¯æ•°", 1, 10, 3)
        
        with col2:
            lora_rank = st.slider("LoRA Rank", 4, 64, 16)
            lora_alpha = st.slider("LoRA Alpha", 8, 128, 32)
            lora_dropout = st.slider("LoRA Dropout", 0.0, 0.3, 0.1)
    
    with st.expander("è©³ç´°è¨­å®š"):
        col1, col2 = st.columns(2)
        
        with col1:
            gradient_accumulation_steps = st.number_input("å‹¾é…è“„ç©ã‚¹ãƒ†ãƒƒãƒ—", 1, 32, 8)
            warmup_steps = st.number_input("ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚¹ãƒ†ãƒƒãƒ—", 0, 1000, 100)
            weight_decay = st.number_input("é‡ã¿æ¸›è¡°", 0.0, 0.1, 0.01, format="%.3f")
        
        with col2:
            save_steps = st.number_input("ä¿å­˜é–“éš”", 100, 2000, 500)
            eval_steps = st.number_input("è©•ä¾¡é–“éš”", 100, 2000, 500)
            early_stopping_patience = st.number_input("æ—©æœŸåœæ­¢å¾…æ©Ÿ", 1, 10, 3)
    
    # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
    if selected_model:
        memory_monitor = MemoryMonitor()
        can_run, message = memory_monitor.can_run_training(selected_model, batch_size)
        
        if can_run:
            st.success(f"âœ… {message}")
        else:
            st.error(f"âŒ {message}")
            suggested_batch_size = memory_monitor.suggest_batch_size(selected_model)
            st.info(f"ğŸ’¡ æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º: {suggested_batch_size}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    st.subheader("ğŸš€ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ")
    
    if selected_dataset_dir and selected_model:
        train_file_path = str(selected_dataset_dir / "train.jsonl")
        
        if st.button("ğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹", type="primary"):
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
            training_config = {
                'batch_size': batch_size,
                'learning_rate': learning_rate,
                'num_epochs': num_epochs,
                'lora_rank': lora_rank,
                'lora_alpha': lora_alpha,
                'lora_dropout': lora_dropout,
                'gradient_accumulation_steps': gradient_accumulation_steps,
                'warmup_steps': warmup_steps,
                'weight_decay': weight_decay,
                'save_steps': save_steps,
                'eval_steps': eval_steps,
                'early_stopping_patience': early_stopping_patience
            }
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
            trainer = TrainingManager(training_config)
            st.session_state['training_manager'] = trainer
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ³ã‚’ç®¡ç†
            if 'training_progress' not in st.session_state:
                st.session_state['training_progress'] = 0
            if 'training_status' not in st.session_state:
                st.session_state['training_status'] = "æº–å‚™ä¸­..."
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
            progress_bar = st.progress(st.session_state['training_progress'])
            status_text = st.empty()
            status_text.text(st.session_state['training_status'])
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
            def update_progress(progress):
                st.session_state['training_progress'] = progress
            
            def update_status(status):
                st.session_state['training_status'] = status
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç„¡ã—ã§å®Ÿè¡Œï¼‰
            try:
                experiment_id = trainer.start_training(
                    selected_model,
                    train_file_path,
                    progress_callback=None,  # ç„¡åŠ¹åŒ–
                    status_callback=None     # ç„¡åŠ¹åŒ–
                )
                
                st.session_state['current_experiment_id'] = experiment_id
                st.success(f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆå®Ÿé¨“ID: {experiment_id}ï¼‰")
                
            except Exception as e:
                st.error(f"âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ç¾åœ¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ³
    if st.session_state.get('training_manager'):
        status = st.session_state['training_manager'].get_training_status()
        
        if status['is_training']:
            # å®Ÿé¨“ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
            experiment_id = status['experiment_id']
            if experiment_id:
                experiment_info = ExperimentTracker().get_experiment(experiment_id)
                
                # å®Ÿé¨“ãŒå®Œäº†ã—ã¦ã„ã‚‹å ´åˆã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                if experiment_info and experiment_info.get('status') == 'completed':
                    st.session_state['training_manager'].is_training = False
                    st.session_state['training_manager'].current_experiment_id = None
                    st.success(f"ğŸ‰ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼å®Ÿé¨“ID: {experiment_id}")
                    st.info("ğŸ“ˆ å®Ÿé¨“å±¥æ­´ãƒšãƒ¼ã‚¸ã§è©³ç´°ãªçµæœã‚’ç¢ºèªã§ãã¾ã™")
                    st.rerun()
                
                elif experiment_info and experiment_info.get('status') == 'failed':
                    st.session_state['training_manager'].is_training = False
                    st.session_state['training_manager'].current_experiment_id = None
                    st.error(f"âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚å®Ÿé¨“ID: {experiment_id}")
                    st.rerun()
                
                else:
                    # å®Ÿè¡Œä¸­è¡¨ç¤º
                    with st.container():
                        st.info(f"ğŸ”„ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œä¸­... (å®Ÿé¨“ID: {experiment_id})")
                        
                        # å®Ÿé¨“ã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
                        if experiment_info:
                            col1, col2 = st.columns(2)
                            with col1:
                                duration = experiment_info.get('duration_seconds', 0)
                                duration_str = f"{duration:.1f}ç§’" if duration is not None else "å®Ÿè¡Œä¸­"
                                st.metric("å®Ÿè¡Œæ™‚é–“", duration_str)
                            with col2:
                                exp_status = experiment_info.get('status', 'running')
                                status_emoji = {"running": "ğŸ”„", "completed": "âœ…", "failed": "âŒ"}
                                st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{status_emoji.get(exp_status, 'â“')} {exp_status}")
                        
                        # åœæ­¢ãƒœã‚¿ãƒ³
                        if st.button("â¹ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢"):
                            st.session_state['training_manager'].stop_current_training()
                            st.warning("â¹ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢è¦æ±‚ã‚’é€ä¿¡ã—ã¾ã—ãŸ")
                        
                        # è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
                        if st.button("ğŸ”„ çŠ¶æ³æ›´æ–°"):
                            st.rerun()
        else:
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°éå®Ÿè¡Œæ™‚ã®è¡¨ç¤º
            if st.session_state.get('current_experiment_id'):
                last_experiment_id = st.session_state['current_experiment_id']
                experiment_info = ExperimentTracker().get_experiment(last_experiment_id)
                
                if experiment_info:
                    if experiment_info.get('status') == 'completed':
                        st.success(f"âœ… æœ€æ–°ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        st.info(f"å®Ÿé¨“ID: {last_experiment_id}")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button("ğŸ“ˆ å®Ÿé¨“è©³ç´°ã‚’è¦‹ã‚‹"):
                                st.switch_page("experiments")
                        with col2:
                            if st.button("ğŸ“¦ é‡å­åŒ–ã«é€²ã‚€"):
                                st.switch_page("quantization")


def quantization_page():
    """é‡å­åŒ–ãƒšãƒ¼ã‚¸"""
    st.title("ğŸ“¦ é‡å­åŒ–")
    
    quantizer = ModelQuantizer()
    
    # llama.cppçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    st.subheader("ğŸ”§ llama.cpp çŠ¶æ…‹")
    
    if quantizer.check_llama_cpp():
        st.success("âœ… llama.cpp ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    else:
        st.error("âŒ llama.cpp ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        st.markdown("""
        **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™:**
        ```bash
        ./setup.sh
        ```
        """)
        return
    
    # é‡å­åŒ–æ–¹æ³•ã®èª¬æ˜
    st.subheader("ğŸ“Š é‡å­åŒ–æ–¹æ³•")
    
    quant_info = quantizer.get_quantization_info()
    methods_df = pd.DataFrame([
        {
            'æ–¹æ³•': method,
            'èª¬æ˜': info['description'],
            'ã‚µã‚¤ã‚ºæ¯”': f"{info['size_ratio']*100:.0f}%",
            'å“è³ª': info['quality']
        }
        for method, info in quant_info['available_methods'].items()
    ])
    
    st.dataframe(methods_df, use_container_width=True)
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
    finetuned_dir = Path("./models/finetuned")
    available_models = []
    
    if finetuned_dir.exists():
        for model_dir in finetuned_dir.iterdir():
            if model_dir.is_dir():
                # MLXãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’æ¤œç´¢
                adapters_file = model_dir / "adapters.safetensors"
                mlx_model_dirs = list(model_dir.glob("mlx_model_*"))
                
                if adapters_file.exists() and mlx_model_dirs:
                    # MLXãƒ¢ãƒ‡ãƒ«ã¨LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®çµ„ã¿åˆã‚ã›
                    mlx_model_path = mlx_model_dirs[0]  # æœ€åˆã®MLXãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
                    model_info = {
                        'path': str(mlx_model_path),
                        'adapters': str(adapters_file),
                        'experiment_id': model_dir.name,
                        'display_name': f'Gemma-2-2b-it + LoRA ({model_dir.name[:8]})'
                    }
                    available_models.append(model_info)
                
                # å¾“æ¥ã®final_modelãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ã‚µãƒãƒ¼ãƒˆ
                final_model_path = model_dir / "final_model"
                if final_model_path.exists():
                    model_info = {
                        'path': str(final_model_path),
                        'adapters': None,
                        'experiment_id': model_dir.name,
                        'display_name': f'Traditional Model ({model_dir.name[:8]})'
                    }
                    available_models.append(model_info)
    
    if available_models:
        selected_model_info = st.selectbox(
            "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«",
            options=available_models,
            format_func=lambda x: x['display_name']
        )
        selected_model_path = selected_model_info['path']
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"**ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«**: {selected_model_info['path']}")
        with col2:
            if selected_model_info['adapters']:
                st.info(f"**LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼**: {selected_model_info['adapters']}")
            else:
                st.info("**ãƒ¢ãƒ‡ãƒ«**: å¾“æ¥å½¢å¼")
    else:
        st.warning("ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        st.info("ä»£ã‚ã‚Šã«ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ç›´æ¥æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™")
        selected_model_path = st.text_input("ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹", placeholder="/path/to/model")
    
    if selected_model_path:
        # ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼
        validation_result = quantizer.validate_model_path(selected_model_path)
        
        if validation_result['is_valid']:
            st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼OK (ã‚µã‚¤ã‚º: {validation_result['model_size_gb']:.1f} GB)")
        else:
            for error in validation_result['errors']:
                st.error(f"âŒ {error}")
            for warning in validation_result['warnings']:
                st.warning(f"âš ï¸ {warning}")
    
    # é‡å­åŒ–è¨­å®š
    st.subheader("âš™ï¸ é‡å­åŒ–è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        quantization_method = st.selectbox(
            "é‡å­åŒ–æ–¹æ³•",
            options=list(quant_info['available_methods'].keys()),
            index=1  # Q5_K_M ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        )
        
        output_name = st.text_input(
            "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å",
            value=f"model-{quantization_method.lower()}",
            help="æ‹¡å¼µå­(.gguf)ã¯è‡ªå‹•ã§è¿½åŠ ã•ã‚Œã¾ã™"
        )
    
    with col2:
        if selected_model_path and validation_result.get('is_valid'):
            input_size = validation_result['model_size_gb']
            estimated_size = quantizer.estimate_output_size(input_size, quantization_method)
            
            st.metric("å…¥åŠ›ã‚µã‚¤ã‚º", f"{input_size:.1f} GB")
            st.metric("æ¨å®šå‡ºåŠ›ã‚µã‚¤ã‚º", f"{estimated_size:.1f} GB")
            st.metric("åœ§ç¸®ç‡", f"{(estimated_size/input_size)*100:.0f}%")
    
    # é‡å­åŒ–å®Ÿè¡Œ
    if selected_model_path and st.button("ğŸš€ é‡å­åŒ–é–‹å§‹", type="primary"):
        output_dir = "./models/quantized"
        os.makedirs(output_dir, exist_ok=True)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def update_progress(progress):
            progress_bar.progress(progress)
        
        def update_status(status):
            status_text.text(status)
        
        with st.spinner("é‡å­åŒ–å‡¦ç†ä¸­..."):
            result = quantizer.full_quantization_pipeline(
                selected_model_path,
                output_dir,
                quantization_method,
                progress_callback=update_progress,
                status_callback=update_status
            )
            
            if result['success']:
                st.success("âœ… é‡å­åŒ–å®Œäº†ï¼")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("GGUF ã‚µã‚¤ã‚º", f"{result.get('gguf_size_mb', 0)/1024:.1f} GB")
                with col2:
                    st.metric("é‡å­åŒ–å¾Œã‚µã‚¤ã‚º", f"{result.get('quantized_size_mb', 0)/1024:.1f} GB")
                with col3:
                    st.metric("åœ§ç¸®ç‡", f"{result.get('compression_ratio', 1)*100:.0f}%")
                
                st.info(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {result['quantized_path']}")
                
                # Ollamaçµ±åˆã®ææ¡ˆ
                if st.button("ğŸ¤– Ollamaã«ç™»éŒ²"):
                    st.session_state['quantized_model_path'] = result['quantized_path']
                    st.switch_page("Ollamaçµ±åˆ")
                    
            else:
                st.error(f"âŒ é‡å­åŒ–ã‚¨ãƒ©ãƒ¼: {result['error']}")


def ollama_page():
    """Ollamaçµ±åˆãƒšãƒ¼ã‚¸"""
    st.title("ğŸ¤– Ollama çµ±åˆ")
    
    integrator = OllamaIntegrator()
    
    # OllamaçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    st.subheader("ğŸ”§ Ollama ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹")
    
    status = integrator.check_ollama_status()
    
    if status['status'] == 'running':
        st.success(f"âœ… Ollama ã‚µãƒ¼ãƒãƒ¼ç¨¼åƒä¸­ ({status['url']})")
        st.info(f"ğŸ“Š ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {status['models_count']} å€‹")
    elif status['status'] == 'not_running':
        st.error("âŒ Ollama ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“")
        if st.button("ğŸš€ Ollama ã‚µãƒ¼ãƒãƒ¼èµ·å‹•"):
            with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
                if integrator.start_ollama_server():
                    st.success("âœ… ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†ï¼")
                    st.rerun()
                else:
                    st.error("âŒ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    else:
        st.error(f"âŒ Ollama ã‚¨ãƒ©ãƒ¼: {status['error']}")
        return
    
    # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    st.subheader("ğŸ“‹ ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«")
    
    models = integrator.list_models()
    if models:
        models_df = pd.DataFrame([
            {
                'ãƒ¢ãƒ‡ãƒ«å': model['name'],
                'ã‚µã‚¤ã‚º': f"{model.get('size', 0) / (1024**3):.1f} GB",
                'æ›´æ–°æ—¥': model.get('modified_at', 'N/A')[:19] if model.get('modified_at') else 'N/A'
            }
            for model in models
        ])
        st.dataframe(models_df, use_container_width=True)
    else:
        st.info("ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²
    st.subheader("â• æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²")
    
    # é‡å­åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
    quantized_dir = Path("./models/quantized")
    available_gguf = []
    
    if quantized_dir.exists():
        available_gguf = list(quantized_dir.glob("*.gguf"))
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰é‡å­åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
    if 'quantized_model_path' in st.session_state:
        available_gguf.insert(0, Path(st.session_state['quantized_model_path']))
    
    if available_gguf:
        selected_gguf = st.selectbox(
            "GGUFãƒ•ã‚¡ã‚¤ãƒ«",
            options=available_gguf,
            format_func=lambda x: x.name
        )
    else:
        st.warning("é‡å­åŒ–æ¸ˆã¿GGUFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        selected_gguf = st.text_input("GGUFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", placeholder="/path/to/model.gguf")
        if selected_gguf:
            selected_gguf = Path(selected_gguf)
    
    if selected_gguf:
        # ãƒ¢ãƒ‡ãƒ«åè¨­å®š
        col1, col2 = st.columns(2)
        
        with col1:
            model_name = st.text_input(
                "ãƒ¢ãƒ‡ãƒ«å",
                value=selected_gguf.stem if hasattr(selected_gguf, 'stem') else "",
                help="è‹±æ•°å­—ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿ä½¿ç”¨å¯èƒ½"
            )
            
            # ãƒ¢ãƒ‡ãƒ«åæ¤œè¨¼
            if model_name:
                validation = integrator.validate_model_name(model_name)
                if not validation['is_valid']:
                    for error in validation['errors']:
                        st.error(f"âŒ {error}")
                for warning in validation['warnings']:
                    st.warning(f"âš ï¸ {warning}")
        
        with col2:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¸æŠ
            templates = integrator.get_system_prompt_templates()
            template_names = list(templates.keys())
            
            selected_template = st.selectbox(
                "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                options=template_names,
                format_func=lambda x: templates[x]['name']
            )
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†
        if selected_template == 'custom':
            system_prompt = st.text_area(
                "ã‚«ã‚¹ã‚¿ãƒ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                height=150,
                placeholder="ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
            )
        else:
            system_prompt = st.text_area(
                "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                value=templates[selected_template]['prompt'],
                height=150
            )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        st.subheader("âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
        
        # ç”¨é€”åˆ¥ãƒ—ãƒªã‚»ãƒƒãƒˆ
        use_cases = ['general', 'creative', 'precise', 'translation', 'coding']
        use_case = st.selectbox(
            "ç”¨é€”",
            options=use_cases,
            format_func=lambda x: {
                'general': 'ä¸€èˆ¬ç”¨é€”',
                'creative': 'å‰µä½œ',
                'precise': 'æ­£ç¢ºæ€§é‡è¦–',
                'translation': 'ç¿»è¨³',
                'coding': 'ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°'
            }[x]
        )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ææ¡ˆã‚’å–å¾—
        optimization = integrator.optimize_parameters(model_name, use_case)
        recommended = optimization['recommended_parameters']
        
        col1, col2 = st.columns(2)
        
        with col1:
            temperature = st.slider(
                "Temperature",
                0.0, 2.0, recommended['temperature'],
                help="å¿œç­”ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§"
            )
            top_p = st.slider(
                "Top P",
                0.0, 1.0, recommended['top_p'],
                help="æ ¸ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"
            )
        
        with col2:
            repeat_penalty = st.slider(
                "Repeat Penalty",
                1.0, 2.0, recommended['repeat_penalty'],
                help="ç¹°ã‚Šè¿”ã—æŠ‘åˆ¶"
            )
            num_ctx = st.selectbox(
                "Context Length",
                options=[2048, 4096, 8192, 16384],
                index=1,
                help="ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·"
            )
        
        # ãƒ¢ãƒ‡ãƒ«ç™»éŒ²å®Ÿè¡Œ
        if st.button("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ç™»éŒ²", type="primary", disabled=not model_name):
            parameters = {
                'temperature': temperature,
                'top_p': top_p,
                'repeat_penalty': repeat_penalty,
                'num_ctx': num_ctx
            }
            
            with st.spinner("ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ä¸­..."):
                result = integrator.create_model_from_gguf(
                    str(selected_gguf),
                    model_name,
                    system_prompt,
                    parameters
                )
                
                if result['success']:
                    st.success("âœ… ãƒ¢ãƒ‡ãƒ«ç™»éŒ²å®Œäº†ï¼")
                    
                    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                    st.subheader("ğŸ§ª ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
                    test_result = integrator.test_model(model_name)
                    
                    if test_result['success']:
                        st.success("âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ")
                        st.write("**ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:**", test_result['prompt'])
                        st.write("**å¿œç­”:**", test_result['response'])
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ•°", test_result.get('eval_count', 0))
                        with col2:
                            duration_ms = test_result.get('eval_duration', 0) / 1_000_000
                            st.metric("å¿œç­”æ™‚é–“", f"{duration_ms:.0f} ms")
                    else:
                        st.error(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_result['error']}")
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                    if 'quantized_model_path' in st.session_state:
                        del st.session_state['quantized_model_path']
                        
                else:
                    st.error(f"âŒ ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    # ãƒ¢ãƒ‡ãƒ«ç®¡ç†
    if models:
        st.subheader("ğŸ—‘ï¸ ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
        
        model_to_delete = st.selectbox(
            "å‰Šé™¤ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
            options=[''] + [model['name'] for model in models],
            format_func=lambda x: "é¸æŠã—ã¦ãã ã•ã„" if x == '' else x
        )
        
        if model_to_delete and st.button("ğŸ—‘ï¸ ãƒ¢ãƒ‡ãƒ«å‰Šé™¤", type="secondary"):
            if st.checkbox("å‰Šé™¤ã‚’ç¢ºèªã—ã¾ã™"):
                result = integrator.delete_model(model_to_delete)
                
                if result['success']:
                    st.success(f"âœ… {result['message']}")
                    st.rerun()
                else:
                    st.error(f"âŒ {result['error']}")


def experiments_page():
    """å®Ÿé¨“å±¥æ­´ãƒšãƒ¼ã‚¸"""
    st.title("ğŸ“ˆ å®Ÿé¨“å±¥æ­´")
    
    experiment_tracker = ExperimentTracker()
    
    # çµ±è¨ˆæƒ…å ±
    stats = experiment_tracker.get_summary_stats()
    
    st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·å®Ÿé¨“æ•°", stats['total_experiments'])
    with col2:
        st.metric("å®Œäº†", stats['completed'])
    with col3:
        st.metric("å¤±æ•—", stats['failed'])
    with col4:
        st.metric("å®Ÿè¡Œä¸­", stats['running'])
    
    if stats['total_experiments'] > 0:
        success_rate = stats['success_rate'] * 100
        avg_duration_hours = stats['average_duration_seconds'] / 3600
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
        with col2:
            st.metric("å¹³å‡å®Ÿè¡Œæ™‚é–“", f"{avg_duration_hours:.1f} æ™‚é–“")
    
    # å®Ÿé¨“ãƒ•ã‚£ãƒ«ã‚¿
    st.subheader("ğŸ” å®Ÿé¨“æ¤œç´¢")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status_filter = st.selectbox(
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
            options=['ã™ã¹ã¦', 'completed', 'failed', 'running'],
            format_func=lambda x: {
                'ã™ã¹ã¦': 'ã™ã¹ã¦',
                'completed': 'å®Œäº†',
                'failed': 'å¤±æ•—',
                'running': 'å®Ÿè¡Œä¸­'
            }[x]
        )
    
    with col2:
        # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        all_experiments = experiment_tracker.list_experiments()
        model_names = list(set([exp.get('model_name', '') for exp in all_experiments]))
        
        model_filter = st.selectbox(
            "ãƒ¢ãƒ‡ãƒ«",
            options=['ã™ã¹ã¦'] + model_names,
            format_func=lambda x: x.split('/')[-1] if x != 'ã™ã¹ã¦' else x
        )
    
    with col3:
        limit = st.number_input("è¡¨ç¤ºä»¶æ•°", 5, 100, 20)
    
    # å®Ÿé¨“ãƒªã‚¹ãƒˆå–å¾—
    experiments = experiment_tracker.list_experiments(
        status=None if status_filter == 'ã™ã¹ã¦' else status_filter,
        model_name=None if model_filter == 'ã™ã¹ã¦' else model_filter,
        limit=limit
    )
    
    if experiments:
        st.subheader("ğŸ“‹ å®Ÿé¨“ä¸€è¦§")
        
        # å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        exp_data = []
        for exp in experiments:
            duration_hours = (exp.get('duration_seconds', 0) / 3600) if exp.get('duration_seconds') else None
            
            exp_data.append({
                'ID': exp['id'][:8],
                'ãƒ¢ãƒ‡ãƒ«': exp['model_name'].split('/')[-1],
                'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': {
                    'completed': 'âœ… å®Œäº†',
                    'failed': 'âŒ å¤±æ•—',
                    'running': 'ğŸ”„ å®Ÿè¡Œä¸­'
                }.get(exp['status'], exp['status']),
                'ä½œæˆæ—¥æ™‚': exp['created_at'][:19],
                'å®Ÿè¡Œæ™‚é–“': f"{duration_hours:.1f}h" if duration_hours else "N/A",
                'æœ€çµ‚æå¤±': exp.get('final_metrics', {}).get('final_loss', 'N/A')
            })
        
        df = pd.DataFrame(exp_data)
        
        # ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªå®Ÿé¨“é¸æŠ
        selected_exp_id = st.selectbox(
            "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹å®Ÿé¨“",
            options=[''] + [exp['id'] for exp in experiments],
            format_func=lambda x: "é¸æŠã—ã¦ãã ã•ã„" if x == '' else f"{x[:8]} - {next(e['model_name'].split('/')[-1] for e in experiments if e['id'] == x)}"
        )
        
        st.dataframe(df, use_container_width=True)
        
        # å®Ÿé¨“è©³ç´°è¡¨ç¤º
        if selected_exp_id:
            exp_detail = experiment_tracker.get_experiment(selected_exp_id)
            
            if exp_detail:
                st.subheader(f"ğŸ“„ å®Ÿé¨“è©³ç´°: {selected_exp_id[:8]}")
                
                # åŸºæœ¬æƒ…å ±
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**åŸºæœ¬æƒ…å ±**")
                    st.write(f"â€¢ ãƒ¢ãƒ‡ãƒ«: {exp_detail['model_name']}")
                    st.write(f"â€¢ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {Path(exp_detail['dataset_path']).name}")
                    st.write(f"â€¢ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {exp_detail['status']}")
                    st.write(f"â€¢ ä½œæˆæ—¥æ™‚: {exp_detail['created_at'][:19]}")
                
                with col2:
                    st.write("**å®Ÿè¡Œæƒ…å ±**")
                    if exp_detail.get('duration_seconds'):
                        st.write(f"â€¢ å®Ÿè¡Œæ™‚é–“: {exp_detail['duration_seconds']/3600:.1f} æ™‚é–“")
                    if exp_detail.get('output_dir'):
                        st.write(f"â€¢ å‡ºåŠ›: {exp_detail['output_dir']}")
                    if exp_detail.get('error'):
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {exp_detail['error']}")
                
                # è¨­å®šè¡¨ç¤º
                with st.expander("âš™ï¸ è¨­å®š"):
                    st.json(exp_detail.get('config', {}))
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                metrics = experiment_tracker.get_experiment_metrics(selected_exp_id)
                
                if metrics:
                    st.subheader("ğŸ“Š å­¦ç¿’æ›²ç·š")
                    
                    # æå¤±ã‚°ãƒ©ãƒ•
                    metrics_df = pd.DataFrame([
                        {
                            'step': m['step'],
                            'loss': m['metrics'].get('loss', 0),
                            'avg_loss': m['metrics'].get('avg_loss', 0)
                        }
                        for m in metrics if 'loss' in m['metrics']
                    ])
                    
                    if not metrics_df.empty:
                        fig = px.line(
                            metrics_df, 
                            x='step', 
                            y=['loss', 'avg_loss'],
                            title='Training Loss'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
                # ãƒ­ã‚°è¡¨ç¤º
                logs = experiment_tracker.get_experiment_logs(selected_exp_id)
                
                if logs:
                    with st.expander("ğŸ“œ ãƒ­ã‚°"):
                        for log in logs[-10:]:  # æœ€æ–°10ä»¶
                            timestamp = log['timestamp'][:19]
                            level = log['level']
                            message = log['message']
                            st.text(f"[{timestamp}] {level}: {message}")
                
                # å®Ÿé¨“æ“ä½œ
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“ å®Ÿé¨“ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                        export_path = f"./experiments/{selected_exp_id}_export.json"
                        if experiment_tracker.export_experiment(selected_exp_id, export_path):
                            st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {export_path}")
                        else:
                            st.error("âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—")
                
                with col2:
                    if st.button("ğŸ—‘ï¸ å®Ÿé¨“å‰Šé™¤", type="secondary"):
                        if st.checkbox("å‰Šé™¤ã‚’ç¢ºèªã—ã¾ã™", key=f"delete_{selected_exp_id}"):
                            if experiment_tracker.delete_experiment(selected_exp_id):
                                st.success("âœ… å®Ÿé¨“ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                st.rerun()
                            else:
                                st.error("âŒ å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        st.info("å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def settings_page():
    """è¨­å®šãƒšãƒ¼ã‚¸"""
    st.title("âš™ï¸ è¨­å®š")
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç·¨é›†
    st.subheader("ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    
    tab1, tab2 = st.tabs(["åŸºæœ¬è¨­å®š", "ãƒ¢ãƒ‡ãƒ«è¨­å®š"])
    
    with tab1:
        try:
            with open('./config/default_config.yaml', 'r', encoding='utf-8') as f:
                config_content = f.read()
            
            edited_config = st.text_area(
                "default_config.yaml",
                value=config_content,
                height=400,
                help="YAMLå½¢å¼ã§è¨­å®šã‚’ç·¨é›†ã—ã¦ãã ã•ã„"
            )
            
            if st.button("ğŸ’¾ åŸºæœ¬è¨­å®šã‚’ä¿å­˜"):
                try:
                    # YAMLæ¤œè¨¼
                    yaml.safe_load(edited_config)
                    
                    with open('./config/default_config.yaml', 'w', encoding='utf-8') as f:
                        f.write(edited_config)
                    
                    st.success("âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    
                except yaml.YAMLError as e:
                    st.error(f"âŒ YAMLå½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as e:
                    st.error(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                    
        except Exception as e:
            st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    with tab2:
        try:
            with open('./config/models.yaml', 'r', encoding='utf-8') as f:
                models_content = f.read()
            
            edited_models = st.text_area(
                "models.yaml",
                value=models_content,
                height=400,
                help="åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š"
            )
            
            if st.button("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä¿å­˜"):
                try:
                    # YAMLæ¤œè¨¼
                    yaml.safe_load(edited_models)
                    
                    with open('./config/models.yaml', 'w', encoding='utf-8') as f:
                        f.write(edited_models)
                    
                    st.success("âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    
                except yaml.YAMLError as e:
                    st.error(f"âŒ YAMLå½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as e:
                    st.error(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                    
        except Exception as e:
            st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.subheader("ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    memory_monitor = MemoryMonitor()
    memory_info = memory_monitor.get_memory_info()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ç·ãƒ¡ãƒ¢ãƒª", f"{memory_info['total_gb']:.1f} GB")
        st.metric("ä½¿ç”¨ãƒ¡ãƒ¢ãƒª", f"{memory_info['used_gb']:.1f} GB")
        st.metric("åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª", f"{memory_info['available_gb']:.1f} GB")
    
    with col2:
        st.metric("ä½¿ç”¨ç‡", f"{memory_info['percent']:.1f}%")
        st.metric("ç©ºããƒ¡ãƒ¢ãƒª", f"{memory_info['free_gb']:.1f} GB")
    
    # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
    st.subheader("ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡")
    
    directories = {
        "ãƒ‡ãƒ¼ã‚¿": "./data",
        "ãƒ¢ãƒ‡ãƒ«": "./models",
        "å®Ÿé¨“": "./experiments",
        "ãƒ­ã‚°": "./logs"
    }
    
    for name, path in directories.items():
        if os.path.exists(path):
            size = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(path)
                for filename in filenames
            ) / (1024**3)  # GB
            
            st.metric(name, f"{size:.2f} GB")
        else:
            st.metric(name, "0 GB")


# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    try:
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        selected_page = sidebar_menu()
        
        # ãƒšãƒ¼ã‚¸è¡¨ç¤º
        if selected_page == "home":
            home_page()
        elif selected_page == "dataset":
            dataset_page()
        elif selected_page == "training":
            training_page()
        elif selected_page == "quantization":
            quantization_page()
        elif selected_page == "ollama":
            ollama_page()
        elif selected_page == "experiments":
            experiments_page()
        elif selected_page == "settings":
            settings_page()
            
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        logger.exception("Application error")


if __name__ == "__main__":
    main()