import os
import json
import time
import logging
from typing import Dict, Any, Optional, Callable, List, Tuple
from pathlib import Path
import threading
import mlx.core as mx
import mlx.nn as nn
from mlx_lm import load, generate, convert
from mlx_lm.utils import load_config
from mlx_lm.tuner import train, linear_to_lora_layers, TrainingArgs
from mlx_lm.tuner.lora import LoRALinear
import mlx.optimizers as optim
from transformers import AutoTokenizer
import numpy as np

from .experiment_tracker import ExperimentTracker


class MLXFineTuner:
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.experiment_tracker = ExperimentTracker()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self.default_config = {
            'batch_size': 1,
            'learning_rate': 5e-5,
            'num_epochs': 3,
            'lora_rank': 16,
            'lora_alpha': 32,
            'lora_dropout': 0.1,
            'max_seq_length': 2048,
            'save_steps': 500,
            'logging_steps': 10,
            'warmup_steps': 100,
            'weight_decay': 0.01
        }
        
        # è¨­å®šã‚’ãƒãƒ¼ã‚¸
        for key, value in self.default_config.items():
            if key not in self.config:
                self.config[key] = value
    
    def validate_and_convert_local_model(
        self, 
        model_name: str, 
        output_dir: str,
        status_callback: Optional[Callable] = None
    ) -> Tuple[bool, str]:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨MLXå½¢å¼ã¸ã®å¤‰æ›"""
        
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            local_model_path = Path(f"./models/{model_name.split('/')[-1]}")
            
            if status_callback:
                status_callback(f"ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªä¸­: {local_model_path}")
            
            if not local_model_path.exists():
                error_msg = f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {local_model_path}"
                self.logger.error(error_msg)
                if status_callback:
                    status_callback(error_msg)
                return False, f"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {local_model_path}"
            
            # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            required_files = [
                "config.json", 
                "model.safetensors.index.json"
            ]
            
            # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªï¼ˆã©ã¡ã‚‰ã‹ä¸€æ–¹ãŒã‚ã‚Œã°OKï¼‰
            tokenizer_files = ["tokenizer.json", "tokenizer.model"]
            has_tokenizer = any((local_model_path / f).exists() for f in tokenizer_files)
            
            # safetensorsãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            safetensors_files = list(local_model_path.glob("model-*.safetensors"))
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            missing_files = []
            for file in required_files:
                if not (local_model_path / file).exists():
                    missing_files.append(file)
            
            if not has_tokenizer:
                missing_files.append("tokenizer.json ã¾ãŸã¯ tokenizer.model")
            
            if len(safetensors_files) == 0:
                missing_files.append("model-*.safetensors")
            
            if missing_files:
                error_msg = f"âŒ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³: {', '.join(missing_files)}"
                self.logger.error(error_msg)
                if status_callback:
                    status_callback(error_msg)
                return False, f"å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_files}"
            
            self.logger.info(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼å®Œäº†: {local_model_path}")
            if status_callback:
                status_callback(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’æ¤œè¨¼å®Œäº†")
            
            # MLXå½¢å¼ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼‰
            import time
            timestamp = str(int(time.time()))
            mlx_model_dir = Path(output_dir) / f"mlx_model_{timestamp}"
            
            # æ—¢å­˜ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°å‰Šé™¤
            if mlx_model_dir.exists():
                import shutil
                self.logger.info(f"æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤: {mlx_model_dir}")
                shutil.rmtree(mlx_model_dir, ignore_errors=True)
                
            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            mlx_model_dir.parent.mkdir(parents=True, exist_ok=True)
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰MLXå½¢å¼ã«å¤‰æ›
            if status_callback:
                status_callback(f"ğŸ”„ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’MLXå½¢å¼ã«å¤‰æ›ä¸­...")
            
            convert(
                hf_path=str(local_model_path),
                mlx_path=str(mlx_model_dir),
                quantize=False,  # é‡å­åŒ–ã¯ã—ãªã„ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰
                dtype="float16"  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ãŸã‚fp16ã‚’ä½¿ç”¨
            )
            
            if status_callback:
                status_callback("âœ… MLXå¤‰æ›å®Œäº†")
            
            self.logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«å¤‰æ›å®Œäº†: {mlx_model_dir}")
            return True, str(mlx_model_dir)
                    
        except Exception as e:
            error_msg = f"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg)
            if status_callback:
                status_callback(f"âŒ {error_msg}")
            return False, error_msg
    
    def load_model_and_tokenizer(
        self, 
        model_path: str
    ) -> Tuple[nn.Module, AutoTokenizer]:
        """MLXãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        
        try:
            self.logger.info(f"MLXãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path}")
            
            # MLX-LMã®loadé–¢æ•°ã‚’ä½¿ç”¨
            model, tokenizer = load(model_path)
            
            self.logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            return model, tokenizer
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def apply_lora_layers(
        self, 
        model: nn.Module
    ) -> nn.Module:
        """LoRAãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨"""
        
        try:
            rank = self.config.get('lora_rank', 16)
            alpha = self.config.get('lora_alpha', 32)
            dropout = self.config.get('lora_dropout', 0.1)
            
            # LoRAã‚’é©ç”¨ã™ã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç‰¹å®š
            lora_targets = [
                "self_attn.q_proj",
                "self_attn.k_proj", 
                "self_attn.v_proj",
                "self_attn.o_proj",
                "mlp.gate_proj",
                "mlp.up_proj",
                "mlp.down_proj"
            ]
            
            # ãƒ¢ãƒ‡ãƒ«ã«LoRAãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¿½åŠ 
            def apply_lora_to_linear(module, name):
                for target in lora_targets:
                    if target in name and isinstance(module, nn.Linear):
                        # æ—¢å­˜ã®Linearãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’LoRALinearã«ç½®ãæ›ãˆ
                        lora_layer = LoRALinear(
                            input_dims=module.weight.shape[1],
                            output_dims=module.weight.shape[0],
                            r=rank,
                            alpha=alpha,
                            dropout=dropout,
                            bias=module.bias is not None
                        )
                        # å…ƒã®é‡ã¿ã‚’ã‚³ãƒ”ãƒ¼
                        lora_layer.linear.weight = module.weight
                        if module.bias is not None:
                            lora_layer.linear.bias = module.bias
                        
                        return lora_layer
                return module
            
            # ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã«LoRAã‚’é©ç”¨
            model.apply(apply_lora_to_linear)
            
            self.logger.info(f"LoRAé©ç”¨å®Œäº† (rank={rank}, alpha={alpha})")
            return model
            
        except Exception as e:
            self.logger.error(f"LoRAé©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def prepare_dataset(
        self, 
        dataset_path: str, 
        tokenizer: AutoTokenizer
    ) -> List[Dict[str, mx.array]]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–"""
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
            dataset = []
            with open(dataset_path, 'r', encoding='utf-8') as f:
                for line in f:
                    data = json.loads(line.strip())
                    dataset.append(data)
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿: {len(dataset)} ä»¶")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            tokenized_dataset = []
            max_length = self.config.get('max_seq_length', 2048)
            
            for item in dataset:
                text = item.get('text', '')
                
                # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
                tokens = tokenizer(
                    text,
                    max_length=max_length,
                    truncation=True,
                    padding=False,
                    return_tensors=None
                )
                
                # MLXé…åˆ—ã«å¤‰æ›
                input_ids = mx.array(tokens['input_ids'], dtype=mx.int32)
                attention_mask = mx.array(tokens['attention_mask'], dtype=mx.int32)
                
                tokenized_dataset.append({
                    'input_ids': input_ids,
                    'attention_mask': attention_mask,
                    'labels': input_ids  # è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã®ã§labelsã¯input_idsã¨åŒã˜
                })
            
            self.logger.info(f"ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å®Œäº†: {len(tokenized_dataset)} ä»¶")
            return tokenized_dataset
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _get_dataset_size(self, dataset_file: str) -> int:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚’å–å¾—"""
        try:
            with open(dataset_file, 'r', encoding='utf-8') as f:
                return sum(1 for _ in f)
        except Exception as e:
            self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 10  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _verify_training_config(self, output_dir: str) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸè¨­å®šã‚’æ¤œè¨¼"""
        try:
            adapter_config_path = os.path.join(output_dir, "adapter_config.json")
            if os.path.exists(adapter_config_path):
                with open(adapter_config_path, 'r', encoding='utf-8') as f:
                    actual_config = json.load(f)
                
                # é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                return {
                    'iters': actual_config.get('iters', 'unknown'),
                    'learning_rate': actual_config.get('learning_rate', 'unknown'),
                    'batch_size': actual_config.get('batch_size', 'unknown'),
                    'lora_rank': actual_config.get('lora_parameters', {}).get('rank', 'unknown'),
                    'lora_scale': actual_config.get('lora_parameters', {}).get('scale', 'unknown'),
                    'max_seq_length': actual_config.get('max_seq_length', 'unknown')
                }
            else:
                return {'status': 'config_file_not_found'}
        except Exception as e:
            self.logger.warning(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'verification_error', 'error': str(e)}
    
    def compute_loss(
        self, 
        model: nn.Module, 
        batch: Dict[str, mx.array]
    ) -> mx.array:
        """æå¤±ã‚’è¨ˆç®—"""
        
        input_ids = batch['input_ids']
        labels = batch['labels']
        attention_mask = batch['attention_mask']
        
        # ãƒ¢ãƒ‡ãƒ«ã®é †ä¼æ’­
        logits = model(input_ids)
        
        # ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã‚’è¨ˆç®—
        # logits: [batch_size, seq_len, vocab_size]
        # labels: [batch_size, seq_len]
        
        vocab_size = logits.shape[-1]
        
        # logitsã¨labelsã‚’1æ¬¡å…ƒã«å¤‰æ›
        logits_flat = logits.reshape(-1, vocab_size)
        labels_flat = labels.reshape(-1)
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³(-100)ã‚’ç„¡è¦–
        mask = labels_flat != -100
        
        # ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±
        loss = nn.losses.cross_entropy(logits_flat, labels_flat, reduction='none')
        
        # ãƒã‚¹ã‚¯ã‚’é©ç”¨ã—ã¦å¹³å‡ã‚’å–ã‚‹
        loss_masked = loss * mask
        total_loss = mx.sum(loss_masked) / mx.sum(mask)
        
        return total_loss
    
    def run_actual_finetuning(
        self,
        experiment_id: str,
        model_name: str,
        dataset_path: str,
        output_dir: str,
        progress_callback: Optional[Callable] = None,
        status_callback: Optional[Callable] = None
    ):
        """å®Ÿéš›ã®MLXãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼ã¨å¤‰æ›
            if status_callback:
                status_callback("ğŸ”„ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼ã¨å¤‰æ›...")
            
            success, model_path = self.validate_and_convert_local_model(
                model_name, output_dir, status_callback
            )
            
            if not success:
                raise RuntimeError(f"ãƒ¢ãƒ‡ãƒ«æº–å‚™å¤±æ•—: {model_path}")
            
            if progress_callback:
                progress_callback(0.3)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: MLX-LMã®é«˜ãƒ¬ãƒ™ãƒ«APIã‚’ä½¿ç”¨ã—ãŸå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
            if status_callback:
                status_callback("ğŸš€ å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
            
            self._run_mlx_training(
                model_path, dataset_path, experiment_id, output_dir,
                progress_callback, status_callback
            )
            
            if progress_callback:
                progress_callback(1.0)
            
            if status_callback:
                status_callback("ğŸ‰ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
                
        except Exception as e:
            error_msg = f"ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg)
            if status_callback:
                status_callback(f"âŒ {error_msg}")
            raise
    
    def _run_mlx_training(
        self,
        model_path: str,
        dataset_path: str,
        experiment_id: str,
        output_dir: str,
        progress_callback: Optional[Callable] = None,
        status_callback: Optional[Callable] = None
    ):
        """MLX-LMã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""
        
        try:
            import subprocess
            import threading
            import time
            
            if status_callback:
                status_callback("ğŸš€ MLX-LMã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
            
            # MLX-LMç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™
            dataset_dir = os.path.join(output_dir, "dataset")
            os.makedirs(dataset_dir, exist_ok=True)
            
            # train.jsonlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆå…ƒã®dataset.jsonlã‚’ã‚³ãƒ”ãƒ¼ï¼‰
            train_file = os.path.join(dataset_dir, "train.jsonl")
            import shutil
            shutil.copy2(dataset_path, train_file)
            
            # æœ€å°é™ã®valid.jsonlã¨test.jsonlã‚’ä½œæˆï¼ˆMLX-LMãŒæœŸå¾…ã™ã‚‹æ§‹é€ ï¼‰
            valid_file = os.path.join(dataset_dir, "valid.jsonl")
            test_file = os.path.join(dataset_dir, "test.jsonl")
            
            # æœ€å°é™ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ã ã¨IndexErrorã«ãªã‚‹ï¼‰
            dummy_data = '{"text": "### æŒ‡ç¤º:\\nãƒ†ã‚¹ãƒˆ\\n\\n### å›ç­”:\\nãƒ†ã‚¹ãƒˆã§ã™ã€‚"}\n'
            
            with open(valid_file, 'w', encoding='utf-8') as f:
                f.write(dummy_data)
            with open(test_file, 'w', encoding='utf-8') as f:
                f.write(dummy_data)
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: {dataset_dir}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’å‹•çš„ã«è¨ˆç®—
            dataset_size = self._get_dataset_size(train_file)
            
            # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã‚’æ­£ã—ãè¨ˆç®—
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºãŒå°ã•ã„å ´åˆã¯ã€ååˆ†ãªã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã‚’ç¢ºä¿
            epochs = self.config.get('num_epochs', 3)
            if dataset_size <= 10:
                # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å ´åˆã¯ååˆ†ãªã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
                total_iters = max(200, epochs * dataset_size * 10)  # æœ€ä½200å›
            else:
                total_iters = epochs * dataset_size
            
            # LoRAè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            config_file = os.path.join(output_dir, "lora_config.yaml")
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(f"""# LoRA Fine-tuning Configuration
model: {model_path}
train: true
data: {dataset_dir}
fine_tune_type: lora
batch_size: {self.config.get('batch_size', 1)}
iters: {total_iters}
learning_rate: {self.config.get('learning_rate', 5e-5)}
steps_per_report: {self.config.get('logging_steps', 10)}
save_every: {min(100, total_iters // 4)}
adapter_path: {output_dir}
max_seq_length: {self.config.get('max_seq_length', 2048)}
val_batches: 0

# LoRA Parameters
lora_parameters:
  rank: {self.config.get('lora_rank', 16)}
  alpha: {self.config.get('lora_alpha', 32)}
  dropout: {self.config.get('lora_dropout', 0.1)}
  scale: {self.config.get('lora_alpha', 32) / self.config.get('lora_rank', 16)}
""")
            
            # MLX-LMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰
            cmd = [
                "python", "-m", "mlx_lm", "lora",
                "--config", config_file
            ]
            
            self.logger.info(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
            
            # ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                cwd=os.getcwd()
            )
            
            step_count = 0
            total_steps = total_iters  # æ­£ã—ã„ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’ä½¿ç”¨
            
            # å‡ºåŠ›ã‚’ç›£è¦–
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                    
                if output.strip():
                    self.logger.info(f"MLX-LM: {output.strip()}")
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ±ã‚’è§£æ
                    if "Iter" in output and "Loss" in output:
                        try:
                            # "Iter 10: Loss: 1.234" ã®ã‚ˆã†ãªå½¢å¼ã‚’è§£æ
                            parts = output.split()
                            for i, part in enumerate(parts):
                                if part == "Iter" and i + 1 < len(parts):
                                    step_str = parts[i + 1].rstrip(":")
                                    step_count = int(step_str)
                                    break
                                if part == "Loss:" and i + 1 < len(parts):
                                    loss_str = parts[i + 1]
                                    loss = float(loss_str)
                                    
                                    if status_callback:
                                        status_callback(f"ğŸ”„ Step {step_count} - Loss: {loss:.4f}")
                                    
                                    # å®Ÿé¨“ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                                    self.experiment_tracker.log_metrics(
                                        experiment_id,
                                        step=step_count,
                                        metrics={
                                            'loss': loss,
                                            'learning_rate': self.config.get('learning_rate', 5e-5)
                                        }
                                    )
                                    
                                    if progress_callback:
                                        progress = 0.3 + min(0.6, 0.6 * step_count / total_steps)
                                        progress_callback(progress)
                                    break
                        except (ValueError, IndexError):
                            pass
                    
                    elif "Saving" in output or "adapters.safetensors" in output:
                        if status_callback:
                            status_callback("ğŸ’¾ ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä¿å­˜ä¸­...")
            
            # ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ã‚’å¾…æ©Ÿ
            return_code = process.wait()
            
            if return_code == 0:
                self.logger.info(f"MLX-LMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {output_dir}")
                
                if status_callback:
                    status_callback("ğŸ‰ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã‚’å®Ÿè¡Œ
                actual_config = self._verify_training_config(output_dir)
                
                # å®Ÿé¨“å®Œäº†ã‚’è¨˜éŒ²
                adapter_file = os.path.join(output_dir, "adapters.safetensors")
                self.experiment_tracker.complete_experiment(
                    experiment_id,
                    output_dir=output_dir,
                    metrics={
                        'status': 'completed', 
                        'adapter_file': adapter_file,
                        'final_step': step_count,
                        'configured_params': self.config,
                        'actual_params': actual_config,
                        'total_iterations': total_iters,
                        'dataset_size': dataset_size
                    }
                )
                
                if progress_callback:
                    progress_callback(1.0)
                    
            else:
                raise RuntimeError(f"MLX-LMãƒ—ãƒ­ã‚»ã‚¹ãŒã‚¨ãƒ©ãƒ¼ã§çµ‚äº†: return code {return_code}")
            
        except Exception as e:
            error_msg = f"MLX-LMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg)
            
            # å®Ÿé¨“ã‚’å¤±æ•—ã¨ã—ã¦è¨˜éŒ²
            self.experiment_tracker.fail_experiment(
                experiment_id,
                f"{error_msg} | Config: {self.config} | Command: {' '.join(cmd) if 'cmd' in locals() else 'N/A'}"
            )
            
            if status_callback:
                status_callback(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_msg}")
            
            raise RuntimeError(error_msg)
            self.logger.error(error_msg)
            if status_callback:
                status_callback(f"âŒ {error_msg}")
            raise
    
    def _train_model(
        self,
        model: nn.Module,
        dataset: List[Dict[str, mx.array]], 
        experiment_id: str,
        output_dir: str,
        progress_callback: Optional[Callable] = None,
        status_callback: Optional[Callable] = None
    ):
        """å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’å®Ÿè¡Œ"""
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
        learning_rate = self.config.get('learning_rate', 5e-5)
        optimizer = optim.AdamW(learning_rate=learning_rate)
        
        num_epochs = self.config.get('num_epochs', 3)
        batch_size = self.config.get('batch_size', 1)
        logging_steps = self.config.get('logging_steps', 10)
        save_steps = self.config.get('save_steps', 500)
        
        total_steps = len(dataset) * num_epochs // batch_size
        current_step = 0
        
        self.logger.info(f"è¨“ç·´é–‹å§‹: {total_steps} ã‚¹ãƒ†ãƒƒãƒ—, {num_epochs} ã‚¨ãƒãƒƒã‚¯")
        
        for epoch in range(num_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for i in range(0, len(dataset), batch_size):
                # ãƒãƒƒãƒä½œæˆ
                batch_data = dataset[i:i+batch_size]
                
                # å®Ÿéš›ã®é †ä¼æ’­ã¨æå¤±è¨ˆç®—
                batch_loss = mx.array(0.0)
                
                for item in batch_data:
                    loss = self.compute_loss(model, item)
                    batch_loss += loss
                
                batch_loss = batch_loss / len(batch_data)
                
                # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
                loss_and_grad_fn = nn.value_and_grad(model, self.compute_loss)
                loss_value, grads = loss_and_grad_fn(model, batch_data[0])  # ç°¡ç•¥åŒ–
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                optimizer.update(model, grads)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                current_step += 1
                epoch_loss += float(batch_loss)
                num_batches += 1
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                if progress_callback:
                    base_progress = 0.5 + (0.4 * current_step / total_steps)
                    progress_callback(min(0.9, base_progress))
                
                # ãƒ­ã‚°å‡ºåŠ›
                if current_step % logging_steps == 0:
                    avg_loss = epoch_loss / num_batches
                    
                    log_msg = f"Step {current_step}/{total_steps} - Epoch {epoch+1}/{num_epochs} - Loss: {float(batch_loss):.4f}"
                    self.logger.info(log_msg)
                    
                    if status_callback:
                        status_callback(f"ğŸ”„ {log_msg}")
                    
                    # å®Ÿé¨“ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    self.experiment_tracker.log_metrics(
                        experiment_id,
                        step=current_step,
                        metrics={
                            'loss': float(batch_loss),
                            'avg_loss': avg_loss,
                            'epoch': epoch + 1,
                            'learning_rate': learning_rate
                        }
                    )
                
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                if current_step % save_steps == 0:
                    checkpoint_path = os.path.join(output_dir, f'checkpoint-{current_step}')
                    self._save_checkpoint(model, optimizer, checkpoint_path, current_step)
                    
                    if status_callback:
                        status_callback(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: Step {current_step}")
            
            # ã‚¨ãƒãƒƒã‚¯çµ‚äº†å‡¦ç†
            avg_epoch_loss = epoch_loss / max(1, num_batches)
            epoch_msg = f"âœ… ã‚¨ãƒãƒƒã‚¯ {epoch + 1} å®Œäº† - å¹³å‡æå¤±: {avg_epoch_loss:.4f}"
            self.logger.info(epoch_msg)
            
            if status_callback:
                status_callback(epoch_msg)
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        final_model_path = os.path.join(output_dir, 'final_model')
        self._save_final_model(model, tokenizer, final_model_path, experiment_id)
        
        self.logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº† - æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {final_model_path}")
    
    def _save_checkpoint(
        self, 
        model: nn.Module, 
        optimizer: optim.Optimizer, 
        checkpoint_path: str, 
        step: int
    ):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜"""
        
        os.makedirs(checkpoint_path, exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜
        model_weights = {}
        for name, param in model.named_parameters():
            model_weights[name] = param
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæƒ…å ±
        checkpoint = {
            'step': step,
            'model_state_dict': model_weights,
            'optimizer_state_dict': optimizer.state_dict() if hasattr(optimizer, 'state_dict') else {},
            'config': self.config
        }
        
        # ä¿å­˜
        checkpoint_file = os.path.join(checkpoint_path, 'checkpoint.npz')
        mx.savez(checkpoint_file, **model_weights)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONã§ä¿å­˜
        meta_file = os.path.join(checkpoint_path, 'checkpoint_meta.json')
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump({
                'step': step,
                'config': self.config
            }, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜å®Œäº†: {checkpoint_path}")
    
    def _save_final_model(
        self, 
        model: nn.Module, 
        tokenizer: AutoTokenizer, 
        model_path: str, 
        experiment_id: str
    ):
        """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        
        os.makedirs(model_path, exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜
        model_weights = {}
        for name, param in model.named_parameters():
            model_weights[name] = param
        
        weights_file = os.path.join(model_path, 'model.npz')
        mx.savez(weights_file, **model_weights)
        
        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä¿å­˜
        tokenizer.save_pretrained(model_path)
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä¿å­˜
        model_info = {
            'experiment_id': experiment_id,
            'config': self.config,
            'model_type': 'mlx_lora_finetuned',
            'base_model': self.config.get('model_name', 'unknown'),
            'lora_rank': self.config.get('lora_rank', 16),
            'lora_alpha': self.config.get('lora_alpha', 32),
            'training_steps': 'completed'
        }
        
        config_file = os.path.join(model_path, 'model_config.json')
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
        
        return model_path